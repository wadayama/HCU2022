{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 学習型ISTAによるスパース信号再現\n",
    "本アルゴリズムは、TISTA (Ito, Takabe, Wadayama, 2019)\n",
    "\n",
    "https://ieeexplore.ieee.org/document/8695874\n",
    "\n",
    "をベースとしています(TISTAそのものではありません)。\n",
    "\n",
    "問題設定は次のとおり：\n",
    "* 観測過程は $y = x A^T + w$ とする。\n",
    "* 観測行列$A$は$m \\times n$ 実行列\n",
    "* $A$の各要素はガウス分布（平均0、分散1）に従う。\n",
    "* $x$は長さnのスパースベクトルであり、ガウス・ベルヌーイ分布に従う。\n",
    "* 非ゼロ元の生起確率は$p$であり、非ゼロ要素は平均0、分散1のガウス分布に従う。\n",
    "* $w$は長さmの雑音ベクトルであり、各要素はガウス分布（平均0, 標準偏差sigma）に従う。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 必要なパッケージのインポート"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4402/239078803.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import math\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## グローバル定数の設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 150 # 観測ベクトル次元\n",
    "n = 300 # 元信号ベクトル次元\n",
    "sigma = 0.05 # 雑音の標準偏差\n",
    "mbs   = 20 # ミニバッチサイズ\n",
    "p     = 0.1 # 元信号の非ゼロ元の生起確率\n",
    "A = torch.normal(torch.zeros(m, n), std = 1.0) # 観測行列\n",
    "max_itr = 20 # ISTAの反復回数\n",
    "adam_lr = 0.0001 # Adamの学習率"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ミニバッチ生成関数\n",
    "* mbs $\\times$ n のミニバッチを返す。ひとつの行がスパースベクトルになっている\n",
    "* 非ゼロ要素は確率$p$で生起する\n",
    "* 比ゼロ要素の中身は、平均0, 分散1のガウス分布に従う"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_minibatch():\n",
    "    seq = torch.normal(torch.zeros(mbs, n), 1.0) # ガウス乱数ベクトルの生成\n",
    "    support = torch.bernoulli(p * torch.ones(mbs, n)) # 非ゼロサポートの生成\n",
    "    return seq * support # 要素ごとの積(アダマール積)になることに注意"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習可能なISTA クラス\n",
    "* アルゴリズムの詳細の説明は5章にて。\n",
    "* ２種類の学習可能パラメータが導入されている\n",
    "* 縮小関数として、ソフトしきい値関数を利用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ISTA(nn.Module):\n",
    "    def __init__(self, max_itr):\n",
    "        super(ISTA, self).__init__()\n",
    "        self.beta = nn.Parameter(0.001*torch.ones(max_itr)) # 学習可能ステップサイズパラメータ\n",
    "        self.lam  = nn.Parameter(0.1*torch.ones(max_itr)) # 学習可能縮小パラメータ\n",
    "    def shrinkage(self, x, lam): # 縮小関数 (ソフトしきい値関数)\n",
    "        return (x-lam)*(x-lam > 0).float() + (x + lam)*(x+lam < 0).float()\n",
    "    def forward(self, num_itr):\n",
    "        s = torch.zeros(mbs, n) # 初期探索点\n",
    "        for i in range(num_itr):\n",
    "            r = s + self.beta[i] * (y - s @ A.t()) @ A # @は普通の行列・ベクトル積\n",
    "            s = self.shrinkage(r, self.lam[i]) \n",
    "        return s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 訓練ループ(インクリメンタルトレーニング）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ISTA(max_itr)\n",
    "opt   = optim.Adam(model.parameters(), lr=adam_lr)\n",
    "loss_func = nn.MSELoss()\n",
    "for param in model.named_parameters():\n",
    "    print(param)\n",
    "for gen in range(max_itr):\n",
    "    for i in range(50):\n",
    "        x = gen_minibatch() # 元信号の生成\n",
    "        w = torch.normal(torch.zeros(mbs, m), sigma)\n",
    "        y = torch.mm(x, A.t()) + w # 観測信号の生成\n",
    "        opt.zero_grad()\n",
    "        x_hat = model(gen + 1)\n",
    "        loss  = loss_func(x_hat, x) \n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "    print(gen, loss.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 試験スパース再現\n",
    "\n",
    "学習の完了したモデルを利用して、スパース信号再現を行い、その結果をプロットする"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mbs = 1\n",
    "with torch.no_grad():\n",
    "    x = gen_minibatch()\n",
    "    w = torch.normal(torch.zeros(m), sigma)\n",
    "    y = torch.mm(x, A.t()) + w\n",
    "    s = model(max_itr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 元信号の表示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.grid()\n",
    "plt.plot(range(n), x.view(n).cpu().numpy(), color=\"red\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 再現信号の表示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.grid()\n",
    "plt.plot(range(n), s.view(n).detach().numpy(), color=\"blue\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 重ねて表示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.grid()\n",
    "plt.plot(range(n), x.view(n).detach().numpy(), color=\"red\")\n",
    "plt.plot(range(n), s.view(n).detach().numpy(), color=\"blue\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習可能パラメータの表示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('model.beta = ', model.beta)\n",
    "print('model.lam = ', model.lam)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
